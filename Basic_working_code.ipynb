{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11005205,"sourceType":"datasetVersion","datasetId":6851115},{"sourceId":11005228,"sourceType":"datasetVersion","datasetId":6851134}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:17:33.699432Z","iopub.execute_input":"2025-03-13T05:17:33.699894Z","iopub.status.idle":"2025-03-13T05:17:33.706341Z","shell.execute_reply.started":"2025-03-13T05:17:33.699852Z","shell.execute_reply":"2025-03-13T05:17:33.705118Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/historical-dataset/historical_data/ADANIENT.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:53.923513Z","iopub.execute_input":"2025-03-13T05:12:53.923966Z","iopub.status.idle":"2025-03-13T05:12:53.962679Z","shell.execute_reply.started":"2025-03-13T05:12:53.923927Z","shell.execute_reply":"2025-03-13T05:12:53.961405Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                     timestamp     open     high      low    close  volume  oi\n0    2025-03-10T15:15:00+05:30  2229.80  2230.55  2220.00  2224.40   98264   0\n1    2025-03-10T14:45:00+05:30  2225.40  2234.00  2224.90  2230.35   89785   0\n2    2025-03-10T14:15:00+05:30  2247.70  2249.05  2224.00  2226.00   53973   0\n3    2025-03-10T13:45:00+05:30  2250.95  2252.00  2245.60  2248.70   33624   0\n4    2025-03-10T13:15:00+05:30  2261.00  2261.15  2250.95  2250.95   32525   0\n..                         ...      ...      ...      ...      ...     ...  ..\n632  2025-01-01T11:15:00+05:30  2545.15  2547.85  2532.10  2537.00   64807   0\n633  2025-01-01T10:45:00+05:30  2541.20  2552.75  2539.70  2545.15   96430   0\n634  2025-01-01T10:15:00+05:30  2530.80  2545.00  2530.00  2540.00   95404   0\n635  2025-01-01T09:45:00+05:30  2554.15  2555.00  2518.25  2531.00  450529   0\n636  2025-01-01T09:15:00+05:30  2536.00  2572.35  2527.55  2554.95  392150   0\n\n[637 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>oi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-03-10T15:15:00+05:30</td>\n      <td>2229.80</td>\n      <td>2230.55</td>\n      <td>2220.00</td>\n      <td>2224.40</td>\n      <td>98264</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-03-10T14:45:00+05:30</td>\n      <td>2225.40</td>\n      <td>2234.00</td>\n      <td>2224.90</td>\n      <td>2230.35</td>\n      <td>89785</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-03-10T14:15:00+05:30</td>\n      <td>2247.70</td>\n      <td>2249.05</td>\n      <td>2224.00</td>\n      <td>2226.00</td>\n      <td>53973</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-03-10T13:45:00+05:30</td>\n      <td>2250.95</td>\n      <td>2252.00</td>\n      <td>2245.60</td>\n      <td>2248.70</td>\n      <td>33624</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-03-10T13:15:00+05:30</td>\n      <td>2261.00</td>\n      <td>2261.15</td>\n      <td>2250.95</td>\n      <td>2250.95</td>\n      <td>32525</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>632</th>\n      <td>2025-01-01T11:15:00+05:30</td>\n      <td>2545.15</td>\n      <td>2547.85</td>\n      <td>2532.10</td>\n      <td>2537.00</td>\n      <td>64807</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>633</th>\n      <td>2025-01-01T10:45:00+05:30</td>\n      <td>2541.20</td>\n      <td>2552.75</td>\n      <td>2539.70</td>\n      <td>2545.15</td>\n      <td>96430</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>634</th>\n      <td>2025-01-01T10:15:00+05:30</td>\n      <td>2530.80</td>\n      <td>2545.00</td>\n      <td>2530.00</td>\n      <td>2540.00</td>\n      <td>95404</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>2025-01-01T09:45:00+05:30</td>\n      <td>2554.15</td>\n      <td>2555.00</td>\n      <td>2518.25</td>\n      <td>2531.00</td>\n      <td>450529</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>2025-01-01T09:15:00+05:30</td>\n      <td>2536.00</td>\n      <td>2572.35</td>\n      <td>2527.55</td>\n      <td>2554.95</td>\n      <td>392150</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>637 rows 칑 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# Hyperparameters\nSEQ_LEN = 30  # Number of past days used for prediction\nPRED_LEN = 1  # Predict the next day's price\nD_MODEL = 64  # Transformer model dimension\nNHEAD = 4  # Multi-head attention heads\nNUM_LAYERS = 3  # Transformer layers\nBATCH_SIZE = 32\nEPOCHS = 20\nLR = 0.001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:53.971394Z","iopub.execute_input":"2025-03-13T05:12:53.971732Z","iopub.status.idle":"2025-03-13T05:12:53.989854Z","shell.execute_reply.started":"2025-03-13T05:12:53.971706Z","shell.execute_reply":"2025-03-13T05:12:53.988810Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Load dataset\ndata_dir = \"/kaggle/working/dataset/splits\"\n\n# Function to load and preprocess stock data\ndef load_stock_data(file_path):\n    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n    df = df.sort_values(by='timestamp')\n    df['Return'] = df['close'].pct_change()  # Use returns instead of raw prices\n    df = df.dropna()\n    return df[['Return']].values  # Return as NumPy array\n\n# Prepare dataset for Transformer\nclass StockDataset(Dataset):\n    def __init__(self, data, seq_len=SEQ_LEN, pred_len=PRED_LEN):\n        self.data = data\n        self.seq_len = seq_len\n        self.pred_len = pred_len\n\n    def __len__(self):\n        return len(self.data) - self.seq_len - self.pred_len + 1\n\n    def __getitem__(self, idx):\n        x = self.data[idx:idx + self.seq_len]\n        y = self.data[idx + self.seq_len:idx + self.seq_len + self.pred_len]\n        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:53.990861Z","iopub.execute_input":"2025-03-13T05:12:53.991235Z","iopub.status.idle":"2025-03-13T05:12:54.007998Z","shell.execute_reply.started":"2025-03-13T05:12:53.991199Z","shell.execute_reply":"2025-03-13T05:12:54.006812Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"data_dir = \"/kaggle/input/historical-dataset/historical_data\"  # Path to your dataset folder\nall_data = []\n\n# Load and process each CSV file\nfor file in os.listdir(data_dir):\n    if file.endswith(\".csv\"):\n        file_path = os.path.join(data_dir, file)\n        stock_name = file.replace(\".csv\", \"\")  # Extract stock ticker\n        \n        # Load data\n        df = pd.read_csv(file_path)\n        \n        # Add stock name as a new column\n        df[\"Stock\"] = stock_name\n        \n        # Append to list\n        all_data.append(df)\n\n# Combine all stock data into a single DataFrame\nfinal_dataset = pd.concat(all_data, ignore_index=True)\nfinal_dataset[\"timestamp\"] = pd.to_datetime(final_dataset[\"timestamp\"])  # Convert to datetime format\nfinal_dataset = final_dataset.sort_values(by=[\"timestamp\"])  # Sort by date","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:54.009696Z","iopub.execute_input":"2025-03-13T05:12:54.010072Z","iopub.status.idle":"2025-03-13T05:12:54.424692Z","shell.execute_reply.started":"2025-03-13T05:12:54.010043Z","shell.execute_reply":"2025-03-13T05:12:54.423505Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"final_dataset = final_dataset.drop(columns=[\"oi\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:54.426045Z","iopub.execute_input":"2025-03-13T05:12:54.426389Z","iopub.status.idle":"2025-03-13T05:12:54.433081Z","shell.execute_reply.started":"2025-03-13T05:12:54.426324Z","shell.execute_reply":"2025-03-13T05:12:54.432133Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"print(final_dataset.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:54.434931Z","iopub.execute_input":"2025-03-13T05:12:54.435289Z","iopub.status.idle":"2025-03-13T05:12:54.455213Z","shell.execute_reply.started":"2025-03-13T05:12:54.435258Z","shell.execute_reply":"2025-03-13T05:12:54.454059Z"}},"outputs":[{"name":"stdout","text":"                      timestamp     open     high      low    close  volume  \\\n31211 2025-01-01 09:15:00+05:30   308.70   309.15   307.05   307.25  325458   \n17198 2025-01-01 09:15:00+05:30  2280.00  2305.00  2280.00  2299.00  108780   \n2547  2025-01-01 09:15:00+05:30   292.30   293.65   291.50   293.15  422483   \n11465 2025-01-01 09:15:00+05:30   601.50   603.75   596.50   599.55  572072   \n5732  2025-01-01 09:15:00+05:30  1214.85  1217.90  1213.50  1216.20  423841   \n\n            Stock  \n31211   POWERGRID  \n17198  ASIANPAINT  \n2547         BPCL  \n11465    HINDALCO  \n5732     RELIANCE  \n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# 游릭 Step 2: Encode Categorical Feature (Stock Name)\nlabel_encoder = LabelEncoder()\nfinal_dataset[\"Stock\"] = label_encoder.fit_transform(final_dataset[\"Stock\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:54.456736Z","iopub.execute_input":"2025-03-13T05:12:54.457075Z","iopub.status.idle":"2025-03-13T05:12:54.480594Z","shell.execute_reply.started":"2025-03-13T05:12:54.457029Z","shell.execute_reply":"2025-03-13T05:12:54.479469Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"\n# 游릭 Step 3: Normalize Features\nscaler = MinMaxScaler()\nfeatures = [\"open\", \"high\", \"low\", \"close\", \"volume\"]  # Feature columns\nfinal_dataset[features] = scaler.fit_transform(final_dataset[features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:12:54.481691Z","iopub.execute_input":"2025-03-13T05:12:54.482071Z","iopub.status.idle":"2025-03-13T05:12:54.506201Z","shell.execute_reply.started":"2025-03-13T05:12:54.482035Z","shell.execute_reply":"2025-03-13T05:12:54.505139Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# 游릭 Step 4: Create Sequences for Transformer Input\ndef create_sequences(data, seq_length=30):\n    \"\"\"Converts time series data into sequences for Transformer.\"\"\"\n    sequences, targets = [], []\n    \n    for i in range(len(data) - seq_length):\n        seq = data.iloc[i:i+seq_length]  # Get sequence window\n        target = data.iloc[i+seq_length][\"close\"]  # Predict next close price\n        \n        sequences.append(seq[features].values)  # Extract numerical features\n        targets.append(target)  # Store target\n    \n    return np.array(sequences), np.array(targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:13:03.357639Z","iopub.execute_input":"2025-03-13T05:13:03.358013Z","iopub.status.idle":"2025-03-13T05:13:03.363603Z","shell.execute_reply.started":"2025-03-13T05:13:03.357983Z","shell.execute_reply":"2025-03-13T05:13:03.362351Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Create sequences\nseq_length = 30  # Number of past days to look at\nX, y = create_sequences(final_dataset, seq_length)\n\n# 游릭 Step 5: Train-Test Split\ntrain_size = int(0.8 * len(X))\nX_train, X_test = X[:train_size], X[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]\n\n# Print dataset shapes\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:13:04.321310Z","iopub.execute_input":"2025-03-13T05:13:04.321718Z","iopub.status.idle":"2025-03-13T05:13:29.705753Z","shell.execute_reply.started":"2025-03-13T05:13:04.321686Z","shell.execute_reply":"2025-03-13T05:13:29.704803Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (24945, 30, 5)\nX_test shape: (6237, 30, 5)\ny_train shape: (24945,)\ny_test shape: (6237,)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# 游릭 Convert NumPy Arrays to PyTorch Tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Make y 2D\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n\n# 游릭 Create PyTorch DataLoader\nbatch_size = 32\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:17:38.219130Z","iopub.execute_input":"2025-03-13T05:17:38.219481Z","iopub.status.idle":"2025-03-13T05:17:38.229149Z","shell.execute_reply.started":"2025-03-13T05:17:38.219455Z","shell.execute_reply":"2025-03-13T05:17:38.228175Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# 游릭 Define Transformer Model\nclass StockTransformer(nn.Module):\n    def __init__(self, input_dim, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n        super(StockTransformer, self).__init__()\n        self.embedding = nn.Linear(input_dim, embed_dim)  # Feature embedding\n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, dropout=dropout\n        )\n        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n        self.fc = nn.Linear(embed_dim, 1)  # Output layer (predict next Close price)\n\n    def forward(self, x):\n        x = self.embedding(x)  # Linear projection\n        x = x.permute(1, 0, 2)  # PyTorch Transformer expects (seq_len, batch, feature)\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=0)  # Global average pooling\n        x = self.fc(x)  # Regression output\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:17:41.416144Z","iopub.execute_input":"2025-03-13T05:17:41.416537Z","iopub.status.idle":"2025-03-13T05:17:41.422574Z","shell.execute_reply.started":"2025-03-13T05:17:41.416506Z","shell.execute_reply":"2025-03-13T05:17:41.421458Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:17:43.586926Z","iopub.execute_input":"2025-03-13T05:17:43.587291Z","iopub.status.idle":"2025-03-13T05:17:43.591363Z","shell.execute_reply.started":"2025-03-13T05:17:43.587264Z","shell.execute_reply":"2025-03-13T05:17:43.590452Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# 游릭 Initialize Model, Loss, Optimizer\ninput_dim = X_train.shape[2]  # Number of features\nembed_dim = 64\nnum_heads = 4\nff_dim = 128\nnum_layers = 3\ndropout = 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:17:55.456696Z","iopub.execute_input":"2025-03-13T05:17:55.457050Z","iopub.status.idle":"2025-03-13T05:17:55.461549Z","shell.execute_reply.started":"2025-03-13T05:17:55.457023Z","shell.execute_reply":"2025-03-13T05:17:55.460376Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"model = StockTransformer(input_dim, embed_dim, num_heads, ff_dim, num_layers, dropout).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# 游릭 Train the Model\nnum_epochs = 50\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n        optimizer.zero_grad()\n        predictions = model(X_batch)\n        loss = criterion(predictions, y_batch)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:17:56.569232Z","iopub.execute_input":"2025-03-13T05:17:56.569619Z","iopub.status.idle":"2025-03-13T05:19:17.789450Z","shell.execute_reply.started":"2025-03-13T05:17:56.569589Z","shell.execute_reply":"2025-03-13T05:19:17.787953Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50, Loss: 0.047723\nEpoch 2/50, Loss: 0.045033\nEpoch 3/50, Loss: 0.044391\nEpoch 4/50, Loss: 0.044286\nEpoch 5/50, Loss: 0.044068\nEpoch 6/50, Loss: 0.044070\nEpoch 7/50, Loss: 0.043886\nEpoch 8/50, Loss: 0.044003\nEpoch 9/50, Loss: 0.043892\nEpoch 10/50, Loss: 0.043805\nEpoch 11/50, Loss: 0.043883\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-6ffe4895a4b3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"# 游릭 Evaluate the Model\nmodel.eval()\nwith torch.no_grad():\n    total_loss = 0\n    for X_batch, y_batch in test_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        predictions = model(X_batch)\n        loss = criterion(predictions, y_batch)\n        total_loss += loss.item()\n\nprint(f\"Test Loss: {total_loss / len(test_loader):.6f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}