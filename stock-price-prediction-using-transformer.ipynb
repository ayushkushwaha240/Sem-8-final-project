{"cells":[{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:26.741170Z","iopub.status.busy":"2025-03-13T06:04:26.740843Z","iopub.status.idle":"2025-03-13T06:04:26.745979Z","shell.execute_reply":"2025-03-13T06:04:26.745070Z","shell.execute_reply.started":"2025-03-13T06:04:26.741147Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:26.750414Z","iopub.status.busy":"2025-03-13T06:04:26.750149Z","iopub.status.idle":"2025-03-13T06:04:26.763804Z","shell.execute_reply":"2025-03-13T06:04:26.763077Z","shell.execute_reply.started":"2025-03-13T06:04:26.750392Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:27.176395Z","iopub.status.busy":"2025-03-13T06:04:27.176129Z","iopub.status.idle":"2025-03-13T06:04:27.190876Z","shell.execute_reply":"2025-03-13T06:04:27.190101Z","shell.execute_reply.started":"2025-03-13T06:04:27.176367Z"},"trusted":true},"outputs":[],"source":["class StockDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.tensor(X, dtype=torch.float32)  # Keep on CPU\n","        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Keep on CPU\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]  # Do NOT move to GPU here\n"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:50.805124Z","iopub.status.busy":"2025-03-13T06:04:50.804799Z","iopub.status.idle":"2025-03-13T06:04:50.810790Z","shell.execute_reply":"2025-03-13T06:04:50.810090Z","shell.execute_reply.started":"2025-03-13T06:04:50.805088Z"},"trusted":true},"outputs":[],"source":["class StockTransformer(nn.Module):\n","    def __init__(self, input_dim, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n","        super(StockTransformer, self).__init__()\n","        self.embedding = nn.Linear(input_dim, embed_dim)  # Feature embedding\n","        self.encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(embed_dim, 1)  # Output layer (predict next Close price)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)  # Linear projection\n","        x = self.transformer_encoder(x)\n","        x = x.mean(dim=1)  # Global average pooling\n","        x = self.fc(x)  # Regression output\n","        return x"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:27.168955Z","iopub.status.busy":"2025-03-13T06:04:27.168702Z","iopub.status.idle":"2025-03-13T06:04:27.174011Z","shell.execute_reply":"2025-03-13T06:04:27.173178Z","shell.execute_reply.started":"2025-03-13T06:04:27.168917Z"},"trusted":true},"outputs":[],"source":["def create_sequences(data, seq_length=30):\n","    \"\"\"Converts time series data into sequences for Transformer.\"\"\"\n","    sequences, targets = [], []\n","    \n","    for i in range(len(data) - seq_length):\n","        seq = data.iloc[i:i+seq_length]  # Get sequence window\n","        target = data.iloc[i+seq_length][\"close\"]  # Predict next close price\n","        \n","        sequences.append(seq[features].values)  # Extract numerical features\n","        targets.append(target)  # Store target\n","    \n","    return np.array(sequences), np.array(targets)"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:26.765250Z","iopub.status.busy":"2025-03-13T06:04:26.764905Z","iopub.status.idle":"2025-03-13T06:04:26.778977Z","shell.execute_reply":"2025-03-13T06:04:26.778152Z","shell.execute_reply.started":"2025-03-13T06:04:26.765216Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","SEQ_LEN = 30  # Number of past days used for prediction\n","PRED_LEN = 1  # Predict the next day's price\n","D_MODEL = 64  # Transformer model dimension\n","NHEAD = 4  # Multi-head attention heads\n","NUM_LAYERS = 3  # Transformer layers\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","LR = 0.001"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:26.780936Z","iopub.status.busy":"2025-03-13T06:04:26.780725Z","iopub.status.idle":"2025-03-13T06:04:27.115244Z","shell.execute_reply":"2025-03-13T06:04:27.114494Z","shell.execute_reply.started":"2025-03-13T06:04:26.780915Z"},"trusted":true},"outputs":[],"source":["data_dir = \"/kaggle/input/historical-dataset/historical_data\"  # Path to your dataset folder\n","all_data = []\n","\n","# Load and process each CSV file\n","for file in os.listdir(data_dir):\n","    if file.endswith(\".csv\"):\n","        file_path = os.path.join(data_dir, file)\n","        stock_name = file.replace(\".csv\", \"\")  # Extract stock ticker\n","        \n","        # Load data\n","        df = pd.read_csv(file_path)\n","        \n","        # Add stock name as a new column\n","        df[\"Stock\"] = stock_name\n","        \n","        # Append to list\n","        all_data.append(df)\n","\n","# Combine all stock data into a single DataFrame\n","final_dataset = pd.concat(all_data, ignore_index=True)\n","final_dataset[\"timestamp\"] = pd.to_datetime(final_dataset[\"timestamp\"])  # Convert to datetime format\n","final_dataset = final_dataset.sort_values(by=[\"timestamp\"])  # Sort by date"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:27.116912Z","iopub.status.busy":"2025-03-13T06:04:27.116543Z","iopub.status.idle":"2025-03-13T06:04:27.127143Z","shell.execute_reply":"2025-03-13T06:04:27.126422Z","shell.execute_reply.started":"2025-03-13T06:04:27.116873Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                      timestamp     open     high      low    close  volume  \\\n","31211 2025-01-01 09:15:00+05:30   308.70   309.15   307.05   307.25  325458   \n","17198 2025-01-01 09:15:00+05:30  2280.00  2305.00  2280.00  2299.00  108780   \n","2547  2025-01-01 09:15:00+05:30   292.30   293.65   291.50   293.15  422483   \n","11465 2025-01-01 09:15:00+05:30   601.50   603.75   596.50   599.55  572072   \n","5732  2025-01-01 09:15:00+05:30  1214.85  1217.90  1213.50  1216.20  423841   \n","\n","            Stock  \n","31211   POWERGRID  \n","17198  ASIANPAINT  \n","2547         BPCL  \n","11465    HINDALCO  \n","5732     RELIANCE  \n"]}],"source":["final_dataset = final_dataset.drop(columns=[\"oi\"])\n","print(final_dataset.head())"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:27.128398Z","iopub.status.busy":"2025-03-13T06:04:27.128048Z","iopub.status.idle":"2025-03-13T06:04:27.145870Z","shell.execute_reply":"2025-03-13T06:04:27.144982Z","shell.execute_reply.started":"2025-03-13T06:04:27.128363Z"},"trusted":true},"outputs":[],"source":["label_encoder = LabelEncoder()\n","final_dataset[\"Stock\"] = label_encoder.fit_transform(final_dataset[\"Stock\"])\n","scaler = MinMaxScaler()\n","features = [\"open\", \"high\", \"low\", \"close\", \"volume\"]  # Feature columns\n","final_dataset[features] = scaler.fit_transform(final_dataset[features])"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:27.192187Z","iopub.status.busy":"2025-03-13T06:04:27.191873Z","iopub.status.idle":"2025-03-13T06:04:50.778527Z","shell.execute_reply":"2025-03-13T06:04:50.777740Z","shell.execute_reply.started":"2025-03-13T06:04:27.192165Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (24945, 30, 5)\n","X_test shape: (6237, 30, 5)\n","y_train shape: (24945,)\n","y_test shape: (6237,)\n"]}],"source":["# Create sequences\n","seq_length = 30  # Number of past days to look at\n","X, y = create_sequences(final_dataset, seq_length)\n","\n","# ðŸŸ¢ Step 5: Train-Test Split\n","train_size = int(0.8 * len(X))\n","X_train, X_test = X[:train_size], X[train_size:]\n","y_train, y_test = y[:train_size], y[train_size:]\n","\n","# Print dataset shapes\n","print(f\"X_train shape: {X_train.shape}\")\n","print(f\"X_test shape: {X_test.shape}\")\n","print(f\"y_train shape: {y_train.shape}\")\n","print(f\"y_test shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:07:23.682191Z","iopub.status.busy":"2025-03-13T06:07:23.681862Z","iopub.status.idle":"2025-03-13T06:07:23.707211Z","shell.execute_reply":"2025-03-13T06:07:23.705904Z","shell.execute_reply.started":"2025-03-13T06:07:23.682166Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-93-3be1e7224d34>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.X = torch.tensor(X, dtype=torch.float32)  # Keep on CPU\n","<ipython-input-93-3be1e7224d34>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Keep on CPU\n"]}],"source":["# ðŸŸ¢ Convert NumPy Arrays to PyTorch Tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Make y 2D\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n","\n","# ðŸŸ¢ Create PyTorch DataLoader\n","batch_size = 32\n","train_dataset = StockDataset(X_train_tensor, y_train_tensor)\n","test_dataset = StockDataset(X_test_tensor, y_test_tensor)\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=256,  # Try increasing batch size\n","    shuffle=True,\n","    pin_memory=True,  # Keep CPU tensors ready for fast transfer\n","    num_workers=4  # Adjust based on Kaggle CPU cores (try 2, 4, or 8)\n",")\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory = True)"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2025-03-13T06:04:50.811832Z","iopub.status.busy":"2025-03-13T06:04:50.811578Z","iopub.status.idle":"2025-03-13T06:04:50.829943Z","shell.execute_reply":"2025-03-13T06:04:50.829247Z","shell.execute_reply.started":"2025-03-13T06:04:50.811801Z"},"trusted":true},"outputs":[],"source":["input_dim = X_train.shape[2]  # Number of features\n","embed_dim = 64\n","num_heads = 4\n","ff_dim = 128\n","num_layers = 3\n","dropout = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-03-13T06:07:48.476Z","iopub.execute_input":"2025-03-13T06:07:28.283892Z","iopub.status.busy":"2025-03-13T06:07:28.283527Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([256, 1, 1])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50, Loss: 0.055620\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([113, 1, 1])) that is different to the input size (torch.Size([113, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/50, Loss: 0.044490\n","Epoch 3/50, Loss: 0.044499\n","Epoch 4/50, Loss: 0.044595\n","Epoch 5/50, Loss: 0.044339\n","Epoch 6/50, Loss: 0.044773\n","Epoch 7/50, Loss: 0.045343\n","Epoch 8/50, Loss: 0.045010\n","Epoch 9/50, Loss: 0.044600\n","Epoch 10/50, Loss: 0.044637\n","Epoch 11/50, Loss: 0.044352\n","Epoch 12/50, Loss: 0.044433\n","Epoch 13/50, Loss: 0.044476\n","Epoch 14/50, Loss: 0.044388\n","Epoch 15/50, Loss: 0.044537\n"]}],"source":["model = StockTransformer(input_dim, embed_dim, num_heads, ff_dim, num_layers, dropout).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001)  # ðŸš€ AdamW for better GPU optimization\n","\n","num_epochs = 50\n","\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for X_batch, y_batch in train_loader:\n","        optimizer.zero_grad()\n","        X_batch, y_batch = X_batch.to(device, non_blocking=True), y_batch.to(device, non_blocking=True)  # Move to GPU here\n","        predictions = model(X_batch)  # Forward pass\n","        loss = criterion(predictions, y_batch)\n","        loss.backward()  # Backpropagation\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.6f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-03-13T06:06:13.875450Z","iopub.status.idle":"2025-03-13T06:06:13.875856Z","shell.execute_reply":"2025-03-13T06:06:13.875686Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","with torch.no_grad():\n","    total_loss = 0\n","    for X_batch, y_batch in test_loader:\n","        predictions = model(X_batch)\n","        loss = criterion(predictions, y_batch)\n","        total_loss += loss.item()\n","\n","print(f\"Test Loss: {total_loss / len(test_loader):.6f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Prediction Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def prepare_input(new_data, stock_encoder, scaler):\n","    \"\"\"\n","    Prepares stock market input data:\n","    - Encodes stock names numerically\n","    - Converts timestamps to numerical format\n","    - Normalizes all features\n","    - Converts to PyTorch tensor and moves to GPU\n","    \"\"\"\n","    # Convert timestamp to Unix time (seconds since epoch)\n","    new_data[\"timestamp\"] = pd.to_datetime(new_data[\"timestamp\"]).astype(int) // 10**9  \n","\n","    # Encode stock name using provided mapping\n","    new_stock_data[\"stock\"] = new_stock_data[\"stock\"].map(stock_encoder)\n","\n","    # Select relevant columns for model input\n","    feature_columns = [\"timestamp\", \"stock\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n","    input_data = new_data[feature_columns].values  # Convert to numpy array\n","\n","    # Normalize using same scaler as training\n","    input_data_scaled = scaler.transform(input_data)\n","\n","    # Convert to PyTorch tensor and move to GPU\n","    input_tensor = torch.tensor(input_data_scaled, dtype=torch.float32).unsqueeze(0).to(\"cuda\")  \n","    return input_tensor\n","\n","def predict_stock_price(model, new_data_tensor):\n","    \"\"\"\n","    Predicts stock price for a single input.\n","    \"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        prediction = model(new_data_tensor)\n","    return prediction.cpu().numpy()\n","\n","def inverse_transform_prediction(predicted_price, scaler, feature_index=5):  \n","    \"\"\"\n","    Converts normalized predictions back to actual stock prices.\n","    - Assumes 'close' price is at index 5 in the scaler\n","    \"\"\"\n","    temp = np.zeros((predicted_price.shape[0], scaler.n_features_in_))  \n","    temp[:, feature_index] = predicted_price.squeeze()  # Put predictions in the correct column\n","\n","    actual_price = scaler.inverse_transform(temp)[:, feature_index]  # Extract actual price values\n","    return actual_price\n","\n","def predict_future_prices(model, new_data, stock_encoder, scaler, days=10):\n","    \"\"\"\n","    Predicts stock prices for multiple future days using a rolling window.\n","    \"\"\"\n","    future_predictions = []\n","    input_seq = prepare_input(new_data, stock_encoder, scaler)\n","\n","    for _ in range(days):\n","        pred = predict_stock_price(model, input_seq)\n","        future_predictions.append(pred)\n","\n","        # Shift window: Remove first step, add new prediction\n","        pred_tensor = torch.tensor(pred, dtype=torch.float32).unsqueeze(0).to(\"cuda\")\n","        input_seq = torch.cat([input_seq[:, 1:, :], pred_tensor], dim=1)\n","\n","    # Convert predictions back to actual stock prices\n","    actual_predictions = inverse_transform_prediction(np.array(future_predictions), scaler)\n","    return actual_predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stock_encoder = {stock: idx for idx, stock in enumerate(label_encoder.classes_)}\n","\n","# Example new data\n","new_stock_data = pd.DataFrame({\n","    \"timestamp\": [\"2025-01-01 09:15:00+05:30\"],\n","    \"stock\": [\"RELIANCE\"],  \n","    \"open\": [1214.85], \"high\": [1217.90], \"low\": [1213.50], \"close\": [1216.20], \"volume\": [423841]\n","})\n","\n","new_data_tensor = prepare_input(new_stock_data, stock_encoder, scaler)\n","\n","# Single-day prediction\n","predicted_price = predict_stock_price(model, new_data_tensor)\n","actual_price = inverse_transform_prediction(predicted_price, scaler)\n","print(\"Predicted Stock Price:\", actual_price)\n","\n","# Multi-day prediction\n","future_prices = predict_future_prices(model, new_stock_data, stock_encoder, scaler, days=10)\n","print(\"Future Stock Predictions:\", future_prices)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6851115,"sourceId":11005205,"sourceType":"datasetVersion"},{"datasetId":6851134,"sourceId":11005228,"sourceType":"datasetVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
